{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/serciex/lane-change/blob/main/v6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAqx0bsIEQbi"
      },
      "source": [
        "Installing Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AAc_-AeGEE5H",
        "outputId": "c380721b-ae56-4183-8a50-7e3d7590e07f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: highway-env in /usr/local/lib/python3.11/dist-packages (1.10.1)\n",
            "Requirement already satisfied: gymnasium>=1.0.0a2 in /usr/local/lib/python3.11/dist-packages (from highway-env) (1.1.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from highway-env) (0.0.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from highway-env) (2.0.2)\n",
            "Requirement already satisfied: pygame>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from highway-env) (2.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from highway-env) (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from highway-env) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from highway-env) (1.15.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a2->highway-env) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a2->highway-env) (4.14.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->highway-env) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->highway-env) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->highway-env) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->highway-env) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->highway-env) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->highway-env) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->highway-env) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->highway-env) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->highway-env) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->highway-env) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->highway-env) (1.17.0)\n",
            "Requirement already satisfied: stable-baselines3 in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Requirement already satisfied: gymnasium<1.2.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (1.1.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3) (4.14.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pygame\n",
        "!pip install highway-env\n",
        "!pip install stable-baselines3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Civ2P__KEUSq"
      },
      "source": [
        "Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZwGd9eVEWGY"
      },
      "outputs": [],
      "source": [
        "#Import Libraries\n",
        "from os import truncate\n",
        "import math\n",
        "import gymnasium\n",
        "import highway_env\n",
        "from matplotlib import pyplot as plt\n",
        "import pygame\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import tqdm\n",
        "import gym\n",
        "from random import randint\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "import random\n",
        "import torch.optim as optim\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from IPython.display import HTML\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "# Workaround for gym compatibility\n",
        "if not hasattr(np, 'bool8'):\n",
        "    np.bool8 = np.bool_\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Environment Wrapper"
      ],
      "metadata": {
        "id": "t2j5j5Q8Fh9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ENVwrapper(gym.Wrapper):\n",
        " def __init__(self,env,parameters):\n",
        "   super().__init__(env)\n",
        "   self.observation_space = gym.spaces.Box(\n",
        "      low=np.array([\n",
        "          -1000,    # x: position can be negative\n",
        "          -50,      # y: lateral position\n",
        "          0,        # vx: velocity >= 0\n",
        "          -5,       # acceleration: reasonable decel\n",
        "          -np.pi,   # theta: angle bounds\n",
        "          -1,       # lane_id: left lane change\n",
        "          3.0,      # lane_width: minimum width\n",
        "          -np.pi    # self_curvature: angle bounds\n",
        "      ]),\n",
        "      high=np.array([\n",
        "          10000,    # x: far forward position\n",
        "          50,       # y: lateral position\n",
        "          50,       # vx: max highway speed\n",
        "          5,        # acceleration: reasonable accel\n",
        "          np.pi,    # theta: angle bounds\n",
        "          1,        # lane_id: right lane change\n",
        "          4.0,      # lane_width: maximum width\n",
        "          np.pi     # self_curvature: angle bounds\n",
        "      ]),\n",
        "      dtype=np.float32)\n",
        "   self.action_space = gym.spaces.Box(\n",
        "   low=-0.5,  # max left steering\n",
        "   high=0.5,  # max right steering\n",
        "   shape=(1,),\n",
        "   dtype=np.float32\n",
        "   )\n",
        "\n",
        "   self.desired_parameters,self.control_parameters, self.reward_weights, self.following_gap = parameters\n",
        "   self.w1, self.w2, self.w3 = self.reward_weights\n",
        "   self.current_obs = None\n",
        "   self.previous_obs = None\n",
        "\n",
        "   # Add these missing lines:\n",
        "   self.s0, self.v0, self.epsilon = self.desired_parameters\n",
        "   self.a, self.b, self.delta, self.T = self.control_parameters\n",
        "   self.following_gap_threshold = self.following_gap\n",
        "   self.last_lane = None\n",
        "   self.gap_controller_checked = False\n",
        "   self.target_id = 0\n",
        "\n",
        " def lane_check(self):\n",
        "   \"\"\"\n",
        "   Determines which adjacent lane offers the largest front gap for a lane change.\n",
        "   \"\"\"\n",
        "   obs = self.current_obs\n",
        "   ego = self.unwrapped.vehicle\n",
        "   current_lane_id = self.unwrapped.vehicle.lane_index[2]\n",
        "\n",
        "   # Reset flag when lane changes\n",
        "   if self.last_lane is not None and current_lane_id != self.last_lane:\n",
        "       self.gap_controller_checked = False\n",
        "\n",
        "   # Only check if not already checked\n",
        "   if not self.gap_controller_checked:\n",
        "\n",
        "       # Get front gaps using existing longitudinal_lead_state\n",
        "       gap_current_front = obs[1][0]\n",
        "\n",
        "       # Get right lane front gap\n",
        "       current_lane = list(ego.lane_index)\n",
        "       lane_right = (current_lane[0], current_lane[1], current_lane[2] + 1) if current_lane[2] < 2 else ego.lane_index\n",
        "       neighbours_right = self.unwrapped.road.neighbour_vehicles(ego, lane_index=lane_right)\n",
        "       gap_right_front = neighbours_right[0].position[0] - ego.position[0] if neighbours_right and neighbours_right[0] else -float('inf')\n",
        "\n",
        "       # Get left lane front gap\n",
        "       lane_left = (current_lane[0], current_lane[1], current_lane[2] - 1) if current_lane[2] > 0 else ego.lane_index\n",
        "       neighbours_left = self.unwrapped.road.neighbour_vehicles(ego, lane_index=lane_left)\n",
        "       gap_left_front = neighbours_left[0].position[0] - ego.position[0] if neighbours_left and neighbours_left[0] else -float('inf')\n",
        "\n",
        "       # Find best lane\n",
        "       front_gaps = [gap_current_front, gap_right_front, gap_left_front]\n",
        "       best_index = np.argmax(front_gaps)\n",
        "\n",
        "       if best_index == 1:\n",
        "           direction = 1  # Right\n",
        "           gap_right_follower = ego.position[0] - neighbours_right[1].position[0] if len(neighbours_right) > 1 and neighbours_right[1] else float('inf')\n",
        "           self.target_id = direction if gap_right_follower >= self.following_gap_threshold else 0\n",
        "       elif best_index == 2:\n",
        "           direction = -1  # Left\n",
        "           gap_left_follower = ego.position[0] - neighbours_left[1].position[0] if len(neighbours_left) > 1 and neighbours_left[1] else float('inf')\n",
        "           self.target_id = direction if gap_left_follower >= self.following_gap_threshold else 0\n",
        "       else:\n",
        "           self.target_id = 0  # Stay in current lane\n",
        "\n",
        "       self.gap_controller_checked = True\n",
        "\n",
        "   self.last_lane = current_lane_id\n",
        "\n",
        "   return self.target_id\n",
        "\n",
        " def idm_controller(self):\n",
        "   obs = self.current_obs\n",
        "   s0,v0,epsilon = self.desired_parameters\n",
        "   a,b,delta,T = self.control_parameters\n",
        "\n",
        "   v = obs[0][3]\n",
        "   delta_v = obs[0][4]\n",
        "   s = obs[0][5]\n",
        "\n",
        "   # Desired gap: s* = s0 + v*T + (v * delta_v) / (2 * sqrt(a * b))\n",
        "   desired_gap = self.s0 + max(0, v * self.T + ((v * delta_v) / (2 * math.sqrt(self.a * self.b))))\n",
        "\n",
        "   # IDM acceleration: a_IDM = a * [ 1 - (v / v0)^delta - (s* / s)^2 ]\n",
        "   acceleration = self.a * (1 - (v / self.v0)**self.delta - (desired_gap / (s + epsilon))**2)\n",
        "\n",
        "   return acceleration\n",
        "\n",
        " def reward_function(self, obs_old, obs_new):\n",
        "   target_id = self.lane_check()\n",
        "   w1,w2,w3 = self.reward_weights\n",
        "   obs_new = self.current_obs\n",
        "   obs_old = self.previous_obs\n",
        "\n",
        "   \"\"\"\n",
        "   Reward Function:\n",
        "\n",
        "   Acceleration Reward: r_acce = w1*f_acce(a_yaw)\n",
        "   a_yaw = yaw acceleration (rate of change of yaw rate)\n",
        "\n",
        "   Rate Reward: r_rate = w2*f_rate(w_yaw)\n",
        "   w_yaw = yaw rate (rate of change of heading)\n",
        "\n",
        "   Time Reward: r_time = w3*f_time (delta_lat_deviation)\n",
        "   delta_lat_deviation = change in lateral deviation (self.lat_off)\n",
        "\n",
        "   Reward = Cummulative Sum of r_acce + Cummulative Sum of r_rate + Cummulative Sum of r_time\n",
        "\n",
        "   \"\"\"\n",
        "\n",
        "   # Convert direction command to actual target lane\n",
        "   current_lane_id = self.unwrapped.vehicle.lane_index[2]\n",
        "\n",
        "   if target_id == +1:  # Move right\n",
        "       actual_target_lane = min(2, current_lane_id + 1)  # Don't exceed rightmost lane\n",
        "   elif target_id == -1:  # Move left\n",
        "       actual_target_lane = max(0, current_lane_id - 1)  # Don't exceed leftmost lane\n",
        "   else:  # target_id == 0, stay in current lane\n",
        "       actual_target_lane = current_lane_id\n",
        "\n",
        "   # Use current vehicle lane structure and set actual target lane\n",
        "   current_lane_index = list(self.unwrapped.vehicle.lane_index)\n",
        "   current_lane_index[2] = actual_target_lane  # Only change the lane number to actual lane\n",
        "   self.target_lane = tuple(current_lane_index)\n",
        "\n",
        "   target_lane_object = self.unwrapped.road.network.get_lane(self.target_lane)\n",
        "   vehicle_s, _ = self.unwrapped.vehicle.lane.local_coordinates(self.unwrapped.vehicle.position)\n",
        "   _ , self.delta_lat_deviaton = target_lane_object.local_coordinates(self.unwrapped.vehicle.position)\n",
        "\n",
        "   obs = obs_new[0]\n",
        "   obs_old = obs_old[0]\n",
        "\n",
        "   # Extract lateral and longitudinal velocities from observations\n",
        "   vx_current = obs[2]  # longitudinal velocity\n",
        "   vy_current = obs[3]  # lateral velocity\n",
        "   vx_old = obs_old[2]\n",
        "   vy_old = obs_old[3]\n",
        "\n",
        "   dt = 1.0 / self.unwrapped.config['policy_frequency']\n",
        "   L = self.unwrapped.vehicle.LENGTH\n",
        "\n",
        "   # Calculate both yaw rates in parallel using bicycle model\n",
        "   vx_vals = np.array([vx_old, vx_current])\n",
        "   vy_vals = np.array([vy_old, vy_current])\n",
        "\n",
        "   # Vectorized calculations\n",
        "   total_velocities = np.sqrt(vx_vals**2 + vy_vals**2)\n",
        "   curvatures = np.divide(vy_vals, vx_vals * total_velocities + 1e-6,\n",
        "                         out=np.zeros_like(vy_vals), where=(abs(vx_vals) > 1e-6))\n",
        "   yaw_rates = total_velocities * curvatures\n",
        "\n",
        "   previous_yaw_rate, current_yaw_rate = yaw_rates[0], yaw_rates[1]\n",
        "\n",
        "   w_yaw = current_yaw_rate\n",
        "   w_yaw_old = previous_yaw_rate\n",
        "\n",
        "   self.w_acce = (w_yaw-w_yaw_old)*self.unwrapped.config['policy_frequency']\n",
        "\n",
        "   # Acceleration Reward\n",
        "   acce_reward = -w1*abs(self.w_acce)\n",
        "\n",
        "   # Rate Reward\n",
        "   rate_reward = -w2*abs(w_yaw)\n",
        "\n",
        "   # Time Reward\n",
        "   time_reward = -w3*((self.delta_lat_deviaton)**2)\n",
        "\n",
        "   # Off Road\n",
        "   if not self.unwrapped.vehicle.on_road:\n",
        "       off_road_penalty = -10\n",
        "\n",
        "   else:\n",
        "       off_road_penalty = 0\n",
        "\n",
        "   # Overall Reward\n",
        "   self.reward = acce_reward + rate_reward + time_reward + off_road_penalty\n",
        "\n",
        "   return self.reward\n",
        "\n",
        "\n",
        " def step(self, agent_action):\n",
        "   if isinstance(agent_action, np.ndarray):\n",
        "     agent_action = agent_action[0]\n",
        "\n",
        "   obs_old = self.current_obs\n",
        "   vehicle = self.unwrapped.vehicle\n",
        "   idm_action = self.idm_controller()\n",
        "   action = [idm_action, agent_action]\n",
        "\n",
        "   # Prior Observation\n",
        "   v_prev = obs_old[0][2] if obs_old is not None else 0\n",
        "\n",
        "   obs, reward, done, info = super().step(action)\n",
        "   self.previous_obs = obs_old\n",
        "   self.current_obs = obs\n",
        "   custom_reward = self.reward_function(obs_old,obs)\n",
        "\n",
        "   done = done if vehicle.on_road and not info['crashed'] else True\n",
        "\n",
        "   x = obs[0][0]\n",
        "   y = obs[0][1]\n",
        "   vx = obs[0][2]\n",
        "   thetha = obs[0][4]\n",
        "   lane_width = vehicle.lane.width\n",
        "\n",
        "   lane_id = self.lane_check()\n",
        "\n",
        "   self_curvature = vehicle.lane.heading_at(np.clip(\n",
        "       vehicle.lane.local_coordinates(vehicle.position)[0],\n",
        "       0, vehicle.lane.length))\n",
        "\n",
        "   acceleration = (vx-v_prev)*self.unwrapped.config['policy_frequency']\n",
        "\n",
        "   agent_observation = np.array([x,y,vx,acceleration,thetha,lane_id,lane_width,self_curvature], dtype=np.float32)\n",
        "\n",
        "   return agent_observation, custom_reward, done, info\n",
        "\n",
        " def reset(self, **kwargs):\n",
        "   obs, info = super().reset(**kwargs)\n",
        "   self.current_obs = obs\n",
        "   self.previous_obs = None\n",
        "   vehicle = self.unwrapped.vehicle\n",
        "   self.last_lane = None\n",
        "   self.gap_controller_checked = False\n",
        "\n",
        "   obs = obs[0]\n",
        "\n",
        "   x = obs[0]\n",
        "   y = obs[1]\n",
        "   vx = obs[2]\n",
        "   thetha = obs[4]\n",
        "   lane_width = self.unwrapped.vehicle.lane.width\n",
        "\n",
        "   lane_id = self.lane_check()\n",
        "\n",
        "   self_curvature = vehicle.lane.heading_at(np.clip(\n",
        "       vehicle.lane.local_coordinates(vehicle.position)[0],\n",
        "       0, vehicle.lane.length))\n",
        "\n",
        "   acceleration = 0\n",
        "\n",
        "   agent_observation = np.array([x,y,vx,acceleration,thetha,lane_id,lane_width,self_curvature], dtype=np.float32)\n",
        "\n",
        "   return agent_observation, info"
      ],
      "metadata": {
        "id": "FWMYLohR0WZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Environment"
      ],
      "metadata": {
        "id": "0CbmXIUmzlDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialization\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# IDM Parameters\n",
        "desired_parameters = [20, 10.0, 1e-6]      # s0, v0\n",
        "control_parameters = [0.1, 5, 4, 4]        # a, b, δ, T\n",
        "reward_weights = [1,1,0.05]\n",
        "following_gap_threshold = 10\n",
        "parameters = [desired_parameters, control_parameters, reward_weights, following_gap_threshold]\n",
        "\n",
        "# Configure Environment Conditions\n",
        "config = {\n",
        "    \"lanes_count\": 3,\n",
        "    \"lane_width\": 3.75,\n",
        "    \"observation\": {\n",
        "        \"type\": \"Kinematics\",\n",
        "        \"features\": [\"x\", \"y\", \"vx\", \"vy\", \"heading\", \"lat_off\"]\n",
        "    },\n",
        "    \"action\": {\"type\": \"ContinuousAction\"},\"ego_spawn_random\": True,\n",
        "    \"policy_frequency\": 10,\n",
        "}\n",
        "\n",
        "environment = gymnasium.make('highway-v0', render_mode='rgb_array', config=config)\n",
        "env = ENVwrapper(environment,parameters)"
      ],
      "metadata": {
        "id": "QMwQ5TyezmvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop (Stable Baselines)"
      ],
      "metadata": {
        "id": "6lPXFTCN8eu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
        "model.learn(total_timesteps=50000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "gMY396Rx5F1J",
        "outputId": "4103f64f-7713-49b7-ba02-ae8d97a04543"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1000 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 4)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-23-3215398514.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Take action in environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent_action\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}